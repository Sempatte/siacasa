import uuid
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, TYPE_CHECKING

from bot_siacasa.domain.entities.mensaje import Mensaje
from bot_siacasa.domain.entities.usuario import Usuario
from bot_siacasa.domain.entities.conversacion import Conversacion
from bot_siacasa.domain.entities.analisis_sentimiento import AnalisisSentimiento
from bot_siacasa.domain.entities.ticket import Ticket, TicketStatus, EscalationReason
from bot_siacasa.application.interfaces.repository_interface import IRepository
from bot_siacasa.domain.services.escalation_service import EscalationService

# Evitar importaci√≥n circular
if TYPE_CHECKING:
    from bot_siacasa.application.use_cases.analizar_sentimiento_use_case import (
        AnalizarSentimientoUseCase,
    )

logger = logging.getLogger(__name__)


class ChatbotService:
    """
    Servicio principal del chatbot que implementa la l√≥gica de negocio.
    VERSI√ìN OPTIMIZADA con medici√≥n de tiempo precisa y cache.
    ARREGLADO: Mantiene contexto completo de la conversaci√≥n.
    """

    def __init__(
        self, repository: IRepository, sentimiento_analyzer, ai_provider=None, bank_config=None,
        support_repository=None
    ):
        """
        Inicializa el servicio del chatbot.

        Args:
            repository: Repositorio para almacenar datos
            sentimiento_analyzer: Analizador de sentimientos
            ai_provider: Proveedor de IA para generar respuestas
            bank_config: Configuraci√≥n espec√≠fica del banco
            support_repository: Repositorio para tickets de soporte (opcional)
        """
        self.repository = repository
        self.sentimiento_analyzer = sentimiento_analyzer
        self.ai_provider = ai_provider
        self.support_repository = support_repository
        
        # Cache para optimizar rendimiento
        self._sentiment_cache = {}
        self._conversation_cache = {}
        self._max_cache_size = 100
        
        default_config = {
                "bank_name": "Banco",
                "greeting": "Hola, soy SIACASA, tu asistente bancario virtual.",
                "style": "formal"
            }
        
        self.escalation_service = None
        if support_repository:
            self.escalation_service = EscalationService(support_repository)
            logger.info("Escalation service initialized successfully")
        else:
            logger.warning("Support repository not provided, escalation service not initialized")
            
        self.bank_config = {**default_config, **(bank_config or {})}
        
        # Mensaje de sistema que define el comportamiento del chatbot
        self.mensaje_sistema = Mensaje(
            role="system",
            content=f"""
            Eres SIACASA, un asistente bancario virtual dise√±ado para brindar atenci√≥n al cliente 
            del {self.bank_config['bank_name']}. Tu objetivo es proporcionar respuestas precisas, 
            eficientes y emp√°ticas a las consultas de los clientes.
            
            - Identif√≠cate como asistente virtual del {self.bank_config['bank_name']}.
            - Debes ser amable, respetuoso y profesional en todo momento.
            - Adapta tu tono seg√∫n el estado emocional del cliente.
            - Proporciona informaci√≥n clara sobre productos y servicios bancarios.
            - Ayuda a resolver problemas comunes como consultas de saldo, transferencias, etc.
            - Si no puedes resolver una consulta, ofrece derivar al cliente con un agente humano.
            - Recuerda los ultimos mensajes de la conversaci√≥n para mantener el contexto.
            - Si el cliente est√° molesto o frustrado, muestra empat√≠a y ofrece soluciones.
            - Si el cliente est√° satisfecho, agradece su confianza y ofr√©cele m√°s ayuda.
            - Si el cliente est√° confundido, s√© claro y did√°ctico en tus explicaciones.
            - No vuelvas a saludar al cliente en cada respuesta.
            - No uses jerga t√©cnica o t√©rminos complicados.
            - Utiliza un lenguaje sencillo evitando tecnicismos cuando sea posible.
            """
        )

    def obtener_o_crear_conversacion(self, usuario_id: str) -> Conversacion:
        """
        Obtiene una conversaci√≥n existente o crea una nueva.
        OPTIMIZADO: Incluye cache para evitar consultas repetidas.

        Args:
            usuario_id: ID del usuario

        Returns:
            Conversaci√≥n activa
        """
        start_time = time.perf_counter()
        
        try:
            # Verificar cache primero
            if usuario_id in self._conversation_cache:
                cached_conv = self._conversation_cache[usuario_id]
                logger.debug(f"Conversaci√≥n obtenida del cache para {usuario_id}")
                return cached_conv

            # Intentar obtener una conversaci√≥n existente
            conversacion = self.repository.obtener_conversacion_activa(usuario_id)

            # Si no existe, crear una nueva
            if not conversacion:
                # Obtener o crear usuario
                usuario = self.repository.obtener_usuario(usuario_id)
                if not usuario:
                    usuario = Usuario(id=usuario_id)
                    self.repository.guardar_usuario(usuario)

                # Crear nueva conversaci√≥n
                conversacion_id = str(uuid.uuid4())
                conversacion = Conversacion(id=conversacion_id, usuario=usuario)

                # Agregar mensaje del sistema
                conversacion.agregar_mensaje(self.mensaje_sistema)

                # Guardar la conversaci√≥n
                self.repository.guardar_conversacion(conversacion)

            # Agregar al cache (limitar tama√±o)
            self._add_to_conversation_cache(usuario_id, conversacion)
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Conversaci√≥n obtenida/creada en {execution_time:.2f}ms")
            
            return conversacion
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error obteniendo conversaci√≥n en {execution_time:.2f}ms: {e}")
            raise

    def _add_to_conversation_cache(self, usuario_id: str, conversacion: Conversacion):
        """Agrega conversaci√≥n al cache con l√≠mite de tama√±o"""
        if len(self._conversation_cache) >= self._max_cache_size:
            # Remover el m√°s antiguo (FIFO simple)
            oldest_key = next(iter(self._conversation_cache))
            del self._conversation_cache[oldest_key]
        
        self._conversation_cache[usuario_id] = conversacion

    def agregar_mensaje_usuario(self, usuario_id: str, texto: str) -> Mensaje:
        """
        Agrega un mensaje del usuario a la conversaci√≥n.
        OPTIMIZADO: Medici√≥n de tiempo y validaci√≥n de entrada.

        Args:
            usuario_id: ID del usuario
            texto: Texto del mensaje

        Returns:
            Mensaje creado
        """
        start_time = time.perf_counter()
        
        try:
            # Validaci√≥n de entrada
            if not texto or not texto.strip():
                raise ValueError("El texto del mensaje no puede estar vac√≠o")

            conversacion = self.obtener_o_crear_conversacion(usuario_id)

            # Crear mensaje
            mensaje = Mensaje(role="user", content=texto.strip())

            # Agregar a la conversaci√≥n
            conversacion.agregar_mensaje(mensaje)

            # OPTIMIZACI√ìN: Limitar historial para evitar tokens excesivos
            conversacion.limitar_historial(max_mensajes=20)

            # Guardar la conversaci√≥n actualizada
            self.repository.guardar_conversacion(conversacion)
            
            # Actualizar cache
            self._conversation_cache[usuario_id] = conversacion

            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Mensaje usuario agregado en {execution_time:.2f}ms")
            
            return mensaje
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error agregando mensaje usuario en {execution_time:.2f}ms: {e}")
            raise

    def agregar_mensaje_asistente(self, usuario_id: str, texto: str) -> Mensaje:
        """
        Agrega un mensaje del asistente a la conversaci√≥n.
        OPTIMIZADO: Medici√≥n de tiempo y cache actualizado.

        Args:
            usuario_id: ID del usuario
            texto: Texto del mensaje

        Returns:
            Mensaje creado
        """
        start_time = time.perf_counter()
        
        try:
            conversacion = self.obtener_o_crear_conversacion(usuario_id)

            # Crear mensaje
            mensaje = Mensaje(role="assistant", content=texto)

            # Agregar a la conversaci√≥n
            conversacion.agregar_mensaje(mensaje)

            # Guardar la conversaci√≥n actualizada
            self.repository.guardar_conversacion(conversacion)
            
            # Actualizar cache
            self._conversation_cache[usuario_id] = conversacion

            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Mensaje asistente agregado en {execution_time:.2f}ms")
            
            return mensaje
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error agregando mensaje asistente en {execution_time:.2f}ms: {e}")
            raise

    def procesar_mensaje(self, usuario_id: str, texto: str, info_usuario: Dict = None) -> str:
        """
        üî• M√âTODO PRINCIPAL: Procesa un mensaje del usuario manteniendo el contexto COMPLETO.
        CR√çTICO: Este m√©todo asegura que se mantenga el historial de la conversaci√≥n.
        
        Args:
            usuario_id: ID del usuario
            texto: Texto del mensaje del usuario
            info_usuario: Informaci√≥n adicional del usuario
            
        Returns:
            Respuesta generada por la IA
        """
        start_time = time.perf_counter()
        
        try:
            # 1. Obtener conversaci√≥n existente (esto preserva el historial)
            conversacion = self.obtener_o_crear_conversacion(usuario_id)
            
            # 2. DEBUG: Verificar que tenemos mensajes previos
            logger.info(f"üîç CONVERSACI√ìN {usuario_id}: {len(conversacion.mensajes)} mensajes existentes")
            for i, msg in enumerate(conversacion.mensajes[-3:]):  # Log √∫ltimos 3 mensajes
                content_preview = msg.content[:50] + "..." if len(msg.content) > 50 else msg.content
                logger.info(f"  üìù Mensaje {i}: [{msg.role}] {content_preview}")
            
            # 3. Agregar mensaje del usuario a la conversaci√≥n
            mensaje_usuario = self.agregar_mensaje_usuario(usuario_id, texto)
            
            # 4. CR√çTICO: Obtener historial COMPLETO incluyendo mensajes anteriores
            historial_completo = conversacion.obtener_historial()
            
            # 5. Verificar que el historial contiene contexto
            if len(historial_completo) < 2:
                logger.warning(f"‚ö†Ô∏è HISTORIAL MUY CORTO para {usuario_id}: {len(historial_completo)} mensajes")
            else:
                logger.info(f"‚úÖ Enviando {len(historial_completo)} mensajes a la IA para mantener contexto")
            
            # 6. Generar respuesta con TODO el historial (esto mantiene el contexto)
            if not self.ai_provider:
                logger.error("‚ùå AI provider no disponible")
                return "Lo siento, estoy experimentando problemas t√©cnicos."
            
            # 7. Llamar a la IA con el historial completo
            respuesta = self.ai_provider.generar_respuesta(historial_completo)
            
            # 8. Guardar respuesta del asistente
            mensaje_respuesta = Mensaje(
                id=str(uuid.uuid4()),
                role="assistant", 
                content=respuesta,
                timestamp=datetime.now()
            )
            conversacion.agregar_mensaje(mensaje_respuesta)
            
            # 9. CR√çTICO: Guardar la conversaci√≥n actualizada
            self.repository.guardar_conversacion(conversacion)
            
            # 10. Actualizar cache para pr√≥ximas consultas
            self._conversation_cache[usuario_id] = conversacion
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.info(f"‚úÖ Mensaje procesado en {execution_time:.2f}ms con {len(historial_completo)} mensajes de contexto")
            
            return respuesta
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"‚ùå Error procesando mensaje en {execution_time:.2f}ms: {e}", exc_info=True)
            return "Disculpa, ocurri√≥ un error al procesar tu mensaje. ¬øPuedes intentarlo de nuevo?"

    def obtener_historial_mensajes(self, usuario_id: str, limit: int = 20) -> List[Dict[str, str]]:
        """
        M√âTODO OPTIMIZADO: Obtiene el historial limitado directamente.
        
        Args:
            usuario_id: ID del usuario
            limit: L√≠mite de mensajes a obtener

        Returns:
            Lista de mensajes en formato para la API de OpenAI
        """
        start_time = time.perf_counter()
        
        try:
            # Intentar usar el m√©todo optimizado del repositorio si est√° disponible
            if hasattr(self.repository, 'obtener_historial_limitado'):
                historial = self.repository.obtener_historial_limitado(usuario_id, limit)
                execution_time = (time.perf_counter() - start_time) * 1000
                logger.debug(f"Historial limitado obtenido en {execution_time:.2f}ms")
                return historial
            
            # Fallback al m√©todo original con l√≠mite en memoria
            conversacion = self.obtener_o_crear_conversacion(usuario_id)
            historial_completo = conversacion.obtener_historial()
            
            # Aplicar l√≠mite manteniendo mensaje de sistema
            if len(historial_completo) > limit:
                sistema_msgs = [m for m in historial_completo if m.get('role') == 'system']
                otros_msgs = [m for m in historial_completo if m.get('role') != 'system']
                historial_limitado = sistema_msgs + otros_msgs[-(limit - len(sistema_msgs)):]
            else:
                historial_limitado = historial_completo
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Historial fallback obtenido en {execution_time:.2f}ms")
            
            return historial_limitado
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error obteniendo historial en {execution_time:.2f}ms: {e}")
            # Retornar historial m√≠nimo en caso de error
            return [{"role": "system", "content": "Eres un asistente bancario virtual."}]

    def obtener_resumen_conversacion(self, usuario_id: str) -> str:
        """
        Genera un resumen de la conversaci√≥n para mantener contexto.
        OPTIMIZADO: Con medici√≥n de tiempo.
        """
        start_time = time.perf_counter()
        
        try:
            conversacion = self.obtener_o_crear_conversacion(usuario_id)
            
            # Si hay pocos mensajes, no es necesario resumir
            if len(conversacion.mensajes) < 15:
                return ""
            
            # Solicitar un resumen a la IA
            mensajes_para_resumir = conversacion.mensajes[-15:]  # √öltimos 15 mensajes
            mensajes_formateados = [f"{m.role}: {m.content}" for m in mensajes_para_resumir]
            
            instruccion = "Resume brevemente los siguientes intercambios de la conversaci√≥n manteniendo los puntos clave:"
            contenido = "\n".join(mensajes_formateados)
            
            mensajes_resumen = [
                {"role": "system", "content": instruccion},
                {"role": "user", "content": contenido}
            ]
            
            if self.ai_provider:
                respuesta = self.ai_provider.generar_respuesta(mensajes_resumen)
                execution_time = (time.perf_counter() - start_time) * 1000
                logger.debug(f"Resumen generado en {execution_time:.2f}ms")
                return respuesta
            else:
                logger.warning("AI provider no disponible para generar resumen")
                return ""
                
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error generando resumen en {execution_time:.2f}ms: {e}")
            return ""

    def actualizar_datos_usuario(self, usuario_id: str, datos: Dict) -> None:
        """
        Actualiza los datos del usuario.
        OPTIMIZADO: Con medici√≥n de tiempo.

        Args:
            usuario_id: ID del usuario
            datos: Datos a actualizar
        """
        start_time = time.perf_counter()
        
        try:
            usuario = self.repository.obtener_usuario(usuario_id)
            if usuario:
                usuario.datos.update(datos)
                self.repository.guardar_usuario(usuario)
                
                execution_time = (time.perf_counter() - start_time) * 1000
                logger.debug(f"Datos usuario actualizados en {execution_time:.2f}ms")
            else:
                logger.warning(f"Usuario {usuario_id} no encontrado para actualizar datos")
                
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error actualizando datos usuario en {execution_time:.2f}ms: {e}")

    def analizar_sentimiento_mensaje(self, texto: str) -> AnalisisSentimiento:
        """
        Analiza el sentimiento de un mensaje.
        OPTIMIZADO: Con cache inteligente y medici√≥n de tiempo.

        Args:
            texto: Texto a analizar

        Returns:
            An√°lisis de sentimiento
        """
        start_time = time.perf_counter()
        
        try:
            # Crear clave de cache
            cache_key = hash(texto.strip().lower())
            
            # Verificar cache
            if cache_key in self._sentiment_cache:
                execution_time = (time.perf_counter() - start_time) * 1000
                logger.debug(f"Sentimiento obtenido del cache en {execution_time:.2f}ms")
                return self._sentiment_cache[cache_key]
            
            # Analizar sentimiento
            resultado = self.sentimiento_analyzer.execute(texto)
            
            # Agregar al cache con l√≠mite
            if len(self._sentiment_cache) >= self._max_cache_size:
                # Remover elementos antiguos (FIFO simple)
                oldest_key = next(iter(self._sentiment_cache))
                del self._sentiment_cache[oldest_key]
            
            self._sentiment_cache[cache_key] = resultado
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Sentimiento analizado en {execution_time:.2f}ms")
            
            return resultado
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error analizando sentimiento en {execution_time:.2f}ms: {e}")
            
            # Retornar an√°lisis por defecto en caso de error
            class FallbackSentiment:
                sentimiento = "neutral"
                confianza = 0.5
                emociones = []
                entidades = {}
            
            return FallbackSentiment()

    def check_for_escalation(self, mensaje_usuario: str, usuario_id: str) -> bool:
        """
        Verifica si es necesario escalar la conversaci√≥n a un humano.
        OPTIMIZADO: Con medici√≥n de tiempo y mejor manejo de errores.
        
        Args:
            mensaje_usuario: Texto del mensaje del usuario
            usuario_id: ID del usuario
            
        Returns:
            True si es necesario escalar, False en caso contrario
        """
        start_time = time.perf_counter()
        
        try:
            # Si no hay servicio de escalaci√≥n, no se puede escalar
            if not self.escalation_service:
                logger.debug("Escalation service no disponible")
                return False
            
            # Obtener conversaci√≥n activa
            conversacion = self.obtener_o_crear_conversacion(usuario_id)
            
            # Verificar si debe escalar
            should_escalate, reason = self.escalation_service.check_for_escalation(mensaje_usuario, conversacion)
            
            # Si debe escalar, crear ticket
            if should_escalate and reason:
                # Obtener usuario
                usuario = self.repository.obtener_usuario(usuario_id)
                
                # Crear ticket
                ticket = self.escalation_service.create_ticket(conversacion, usuario, reason)
                
                execution_time = (time.perf_counter() - start_time) * 1000
                logger.info(f"Conversaci√≥n escalada en {execution_time:.2f}ms. Ticket creado: {ticket.id}")
                return True
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Verificaci√≥n escalaci√≥n completada en {execution_time:.2f}ms")
            return False
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error verificando escalaci√≥n en {execution_time:.2f}ms: {e}")
            return False

    def esta_escalada(self, usuario_id: str) -> bool:
        """
        Verifica si la conversaci√≥n ya ha sido escalada a un humano.
        OPTIMIZADO: Con medici√≥n de tiempo.
        
        Args:
            usuario_id: ID del usuario
            
        Returns:
            True si ya est√° escalada, False en caso contrario
        """
        start_time = time.perf_counter()
        
        try:
            # Si no hay servicio de escalaci√≥n, no est√° escalada
            if not self.escalation_service:
                return False
            
            # Buscar tickets activos para este usuario
            if hasattr(self.escalation_service.repository, 'obtener_tickets_por_usuario'):
                tickets = self.escalation_service.repository.obtener_tickets_por_usuario(usuario_id)
                
                # Verificar si hay alg√∫n ticket activo (pendiente, asignado o activo)
                for ticket in tickets:
                    if ticket.estado in [TicketStatus.PENDING, TicketStatus.ASSIGNED, TicketStatus.ACTIVE]:
                        execution_time = (time.perf_counter() - start_time) * 1000
                        logger.debug(f"Estado escalaci√≥n verificado en {execution_time:.2f}ms")
                        return True
            
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"Estado escalaci√≥n verificado en {execution_time:.2f}ms")
            return False
            
        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            logger.error(f"Error verificando estado escalaci√≥n en {execution_time:.2f}ms: {e}")
            return False

    def get_performance_stats(self) -> Dict[str, any]:
        """
        Obtiene estad√≠sticas de rendimiento del servicio.
        
        Returns:
            Diccionario con estad√≠sticas de rendimiento
        """
        return {
            'cache_sizes': {
                'sentiment_cache': len(self._sentiment_cache),
                'conversation_cache': len(self._conversation_cache)
            },
            'max_cache_size': self._max_cache_size,
            'escalation_service_available': self.escalation_service is not None,
            'ai_provider_available': self.ai_provider is not None
        }

    def clear_caches(self):
        """
        Limpia todos los caches para liberar memoria.
        """
        start_time = time.perf_counter()
        
        sentiment_cache_size = len(self._sentiment_cache)
        conversation_cache_size = len(self._conversation_cache)
        
        self._sentiment_cache.clear()
        self._conversation_cache.clear()
        
        execution_time = (time.perf_counter() - start_time) * 1000
        logger.info(f"Caches limpiados en {execution_time:.2f}ms. "
                   f"Sentimiento: {sentiment_cache_size}, Conversaciones: {conversation_cache_size}")

    def reiniciar_conversacion(self, usuario_id: str) -> bool:
        """
        Reinicia la conversaci√≥n de un usuario.
        
        Args:
            usuario_id: ID del usuario
            
        Returns:
            True si se reinici√≥ correctamente
        """
        try:
            # Limpiar del cache
            if usuario_id in self._conversation_cache:
                del self._conversation_cache[usuario_id]
            
            # Si hay conversaci√≥n activa, marcarla como inactiva
            conversacion = self.repository.obtener_conversacion_activa(usuario_id)
            if conversacion:
                # Aqu√≠ podr√≠as implementar l√≥gica para archivar la conversaci√≥n
                logger.info(f"Conversaci√≥n reiniciada para usuario {usuario_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error reiniciando conversaci√≥n para {usuario_id}: {e}")
            return False